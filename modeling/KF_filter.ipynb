{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T16:14:48.423526Z",
     "start_time": "2019-10-27T16:14:47.446395Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy dataset\n",
    "- **Triangular** currency pairs: `gbpusd`, `usdjpy`, **`jpygbp`**\n",
    "  - $\\frac{USD}{GBP}\\times\\frac{JPY}{USD}\\times\\frac{GBP}{JPY}=1$. Therefore, the following holds assuming a frictionless market condition:\n",
    "  - $\\log{\\frac{USD}{GBP}}-\\log{\\frac{JPY}{USD}}-\\log{\\frac{GBP}{JPY}}=0.$\n",
    "- Period: One day. May 1st, 2019.\n",
    "- Frequency: 1 minute (=1440 data points per day per currency pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Loading a toy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:43.695068Z",
     "start_time": "2019-10-28T18:29:43.587246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "gbpjpy_DAT_ASCII_GBPJPY_M1_201905.csv\n",
      "gbpusd_DAT_ASCII_GBPUSD_M1_201905.csv\n",
      "usdjpy_DAT_ASCII_USDJPY_M1_201905.csv\n",
      "Complted.\n"
     ]
    }
   ],
   "source": [
    "toy_path = '../dataset/'\n",
    "toy_folders = ['toyset']\n",
    "\n",
    "# csv files have no explicit column header, but column names come in this order.\n",
    "# 'timestamp',  'opening', 'high', 'low', 'close', 'volume'\n",
    "# As we are only interested in timestamp and close prices, we set `usecols` = [0,4], a list of indices\n",
    "col_names = ['timestamp',  'opening', 'high', 'low', 'close', 'volume']\n",
    "usecols = [0, 4]\n",
    "\n",
    "df = {}\n",
    "f = pd.DataFrame(columns=col_names)\n",
    "print(\"Loading...\")\n",
    "for folder in toy_folders:\n",
    "    files = os.listdir(toy_path+folder)\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            print(file)\n",
    "            tmp = pd.read_csv(os.path.join(toy_path, folder, file),\n",
    "                              delimiter=';', header=0, names=col_names, usecols=usecols)\n",
    "            df[file[:6]] = tmp.copy()\n",
    "print(\"Complted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:43.757302Z",
     "start_time": "2019-10-28T18:29:43.752379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gbpjpy', 'gbpusd', 'usdjpy'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion: gbpjpy -> jpygbp\n",
    "- In the raw data set, only gbpjpy exists but we need `jpygbp`\n",
    "  - Very easy to convert: the reciprocal of gbpjpy is `jpygbp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:44.098165Z",
     "start_time": "2019-10-28T18:29:44.076747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190501 000100</td>\n",
       "      <td>145.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190501 000200</td>\n",
       "      <td>145.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190501 000300</td>\n",
       "      <td>145.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190501 000400</td>\n",
       "      <td>145.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190501 000500</td>\n",
       "      <td>145.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31945</th>\n",
       "      <td>20190531 165400</td>\n",
       "      <td>136.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31946</th>\n",
       "      <td>20190531 165500</td>\n",
       "      <td>136.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31947</th>\n",
       "      <td>20190531 165600</td>\n",
       "      <td>136.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31948</th>\n",
       "      <td>20190531 165700</td>\n",
       "      <td>136.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31949</th>\n",
       "      <td>20190531 165800</td>\n",
       "      <td>136.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31950 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close\n",
       "0      20190501 000100  145.451\n",
       "1      20190501 000200  145.465\n",
       "2      20190501 000300  145.459\n",
       "3      20190501 000400  145.453\n",
       "4      20190501 000500  145.450\n",
       "...                ...      ...\n",
       "31945  20190531 165400  136.769\n",
       "31946  20190531 165500  136.765\n",
       "31947  20190531 165600  136.772\n",
       "31948  20190531 165700  136.776\n",
       "31949  20190531 165800  136.765\n",
       "\n",
       "[31950 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['jpygbp'] = df['gbpjpy'].copy()\n",
    "df['jpygbp'].close = df['jpygbp'].close.apply(lambda x: 1.0/x)\n",
    "df.pop('gbpjpy', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:44.261793Z",
     "start_time": "2019-10-28T18:29:44.258148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a list of currency pairs: ['gbpusd', 'usdjpy', 'jpygbp']\n"
     ]
    }
   ],
   "source": [
    "cry_list = list(df.keys())\n",
    "print('We have a list of currency pairs:', cry_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all data points other data May 1, 2019\n",
    "- Also take logs and create a `log_close` column to save log values.\n",
    "- Now we have final observed data points in this column `log_close`\n",
    "- Create a list of numpy(`log_close`) for three currency pairs for easier usage and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:45.183281Z",
     "start_time": "2019-10-28T18:29:45.180945Z"
    }
   },
   "outputs": [],
   "source": [
    "begin_date = '20190501 000100'\n",
    "end_date = '20190501 235900'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We asuume a batch size of 1,440 (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:45.967883Z",
     "start_time": "2019-10-28T18:29:45.965126Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 60*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:46.544963Z",
     "start_time": "2019-10-28T18:29:46.540585Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = pd.DataFrame(pd.Series(pd.date_range(\n",
    "    begin_date[:8], periods=batch_size, freq='1min')), columns=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:47.467698Z",
     "start_time": "2019-10-28T18:29:46.864260Z"
    }
   },
   "outputs": [],
   "source": [
    "for cry in cry_list:\n",
    "    df[cry] = df[cry][df[cry].timestamp.str.startswith('20190501')]\n",
    "    df[cry]['datetime'] = df[cry].timestamp.apply(lambda x: pd.to_datetime(x))\n",
    "    df[cry][cry+'log_close'] = df[cry].close.apply(lambda x: np.log(x))\n",
    "    idx = idx.merge(df[cry], how='left', left_on='datetime', right_on='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T18:29:47.494279Z",
     "start_time": "2019-10-28T18:29:47.470116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>timestamp_x</th>\n",
       "      <th>close_x</th>\n",
       "      <th>gbpusdlog_close</th>\n",
       "      <th>timestamp_y</th>\n",
       "      <th>close_y</th>\n",
       "      <th>usdjpylog_close</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>jpygbplog_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-01 00:01:00</td>\n",
       "      <td>20190501 000100</td>\n",
       "      <td>1.30428</td>\n",
       "      <td>0.265651</td>\n",
       "      <td>20190501 000100</td>\n",
       "      <td>111.488</td>\n",
       "      <td>4.713917</td>\n",
       "      <td>20190501 000100</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>-4.979839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-01 00:02:00</td>\n",
       "      <td>20190501 000200</td>\n",
       "      <td>1.30439</td>\n",
       "      <td>0.265735</td>\n",
       "      <td>20190501 000200</td>\n",
       "      <td>111.489</td>\n",
       "      <td>4.713926</td>\n",
       "      <td>20190501 000200</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>-4.979936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-01 00:03:00</td>\n",
       "      <td>20190501 000300</td>\n",
       "      <td>1.30437</td>\n",
       "      <td>0.265720</td>\n",
       "      <td>20190501 000300</td>\n",
       "      <td>111.489</td>\n",
       "      <td>4.713926</td>\n",
       "      <td>20190501 000300</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>-4.979894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-01 00:04:00</td>\n",
       "      <td>20190501 000400</td>\n",
       "      <td>1.30428</td>\n",
       "      <td>0.265651</td>\n",
       "      <td>20190501 000400</td>\n",
       "      <td>111.489</td>\n",
       "      <td>4.713926</td>\n",
       "      <td>20190501 000400</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>-4.979853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2019-05-01 23:55:00</td>\n",
       "      <td>20190501 235500</td>\n",
       "      <td>1.30544</td>\n",
       "      <td>0.266540</td>\n",
       "      <td>20190501 235500</td>\n",
       "      <td>111.540</td>\n",
       "      <td>4.714383</td>\n",
       "      <td>20190501 235500</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-4.980966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2019-05-01 23:56:00</td>\n",
       "      <td>20190501 235600</td>\n",
       "      <td>1.30550</td>\n",
       "      <td>0.266586</td>\n",
       "      <td>20190501 235600</td>\n",
       "      <td>111.542</td>\n",
       "      <td>4.714401</td>\n",
       "      <td>20190501 235600</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-4.981021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2019-05-01 23:57:00</td>\n",
       "      <td>20190501 235700</td>\n",
       "      <td>1.30546</td>\n",
       "      <td>0.266555</td>\n",
       "      <td>20190501 235700</td>\n",
       "      <td>111.547</td>\n",
       "      <td>4.714446</td>\n",
       "      <td>20190501 235700</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-4.981028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2019-05-01 23:58:00</td>\n",
       "      <td>20190501 235800</td>\n",
       "      <td>1.30544</td>\n",
       "      <td>0.266540</td>\n",
       "      <td>20190501 235800</td>\n",
       "      <td>111.547</td>\n",
       "      <td>4.714446</td>\n",
       "      <td>20190501 235800</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-4.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2019-05-01 23:59:00</td>\n",
       "      <td>20190501 235900</td>\n",
       "      <td>1.30553</td>\n",
       "      <td>0.266609</td>\n",
       "      <td>20190501 235900</td>\n",
       "      <td>111.547</td>\n",
       "      <td>4.714446</td>\n",
       "      <td>20190501 235900</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>-4.981090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datetime      timestamp_x  close_x  gbpusdlog_close  \\\n",
       "0    2019-05-01 00:00:00              NaN      NaN              NaN   \n",
       "1    2019-05-01 00:01:00  20190501 000100  1.30428         0.265651   \n",
       "2    2019-05-01 00:02:00  20190501 000200  1.30439         0.265735   \n",
       "3    2019-05-01 00:03:00  20190501 000300  1.30437         0.265720   \n",
       "4    2019-05-01 00:04:00  20190501 000400  1.30428         0.265651   \n",
       "...                  ...              ...      ...              ...   \n",
       "1435 2019-05-01 23:55:00  20190501 235500  1.30544         0.266540   \n",
       "1436 2019-05-01 23:56:00  20190501 235600  1.30550         0.266586   \n",
       "1437 2019-05-01 23:57:00  20190501 235700  1.30546         0.266555   \n",
       "1438 2019-05-01 23:58:00  20190501 235800  1.30544         0.266540   \n",
       "1439 2019-05-01 23:59:00  20190501 235900  1.30553         0.266609   \n",
       "\n",
       "          timestamp_y  close_y  usdjpylog_close        timestamp     close  \\\n",
       "0                 NaN      NaN              NaN              NaN       NaN   \n",
       "1     20190501 000100  111.488         4.713917  20190501 000100  0.006875   \n",
       "2     20190501 000200  111.489         4.713926  20190501 000200  0.006875   \n",
       "3     20190501 000300  111.489         4.713926  20190501 000300  0.006875   \n",
       "4     20190501 000400  111.489         4.713926  20190501 000400  0.006875   \n",
       "...               ...      ...              ...              ...       ...   \n",
       "1435  20190501 235500  111.540         4.714383  20190501 235500  0.006867   \n",
       "1436  20190501 235600  111.542         4.714401  20190501 235600  0.006867   \n",
       "1437  20190501 235700  111.547         4.714446  20190501 235700  0.006867   \n",
       "1438  20190501 235800  111.547         4.714446  20190501 235800  0.006867   \n",
       "1439  20190501 235900  111.547         4.714446  20190501 235900  0.006867   \n",
       "\n",
       "      jpygbplog_close  \n",
       "0                 NaN  \n",
       "1           -4.979839  \n",
       "2           -4.979936  \n",
       "3           -4.979894  \n",
       "4           -4.979853  \n",
       "...               ...  \n",
       "1435        -4.980966  \n",
       "1436        -4.981021  \n",
       "1437        -4.981028  \n",
       "1438        -4.981042  \n",
       "1439        -4.981090  \n",
       "\n",
       "[1440 rows x 10 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extended Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Problem setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\mathbf{X}$ is the hidden state estimate and we take it as the estimate of currency intrinsic values.\n",
    "- $\\mathbf{Y}_t$ is the observed values of FX rates at time step $t$.\n",
    "  - An observed data point, i.e., an FX rate is denoted by $y_t^{c_i,c_j}$ for a time step $t$, where $c_ic_j \\in C := \\{gbpusd, usdjpy, jpygbp\\}$ and $i\\neq j. 1=gbp, 2=usd, 3=jpy$.\n",
    "  - Three data points: $y_t^{gbpusd}, y_t^{usdjpy}, y_t^{jpygbp}$ at a time step $t$\n",
    "  - $\\mathbf{Y}_t = [y_t^{gbpusd}, y_t^{usdjpy}, y_t^{jpygbp}]$\n",
    "- We observe data for time step $1:t$, so $\\mathbf{Y}$ is a (T, 3) matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now think of a simple model:\n",
    "$$\\mathbf{X}_{t+1} = \\mathbf{f}(\\mathbf{X}_t) + \\mathbf{Q}_t$$\n",
    "$$\\mathbf{Y}_t = \\mathbf{h}(\\mathbf{X}_t)+\\mathbf{R}_t$$,\n",
    "where $\\mathbf{f}$ and $\\mathbf{h}$ are non-linear functions. If they were linear, it would have been"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximation of $\\mathbf{f(X_t)}$ using Taylor's expansion:\n",
    "$$\\mathbf{f(X_t)} \\approx \\mathbf{f}(p)+\\nabla \\mathbf{f}|_p(\\mathbf{X}_t-p)=\\mathbf{f}(p)+ \\mathbf{H}_t(\\mathbf{X}_t-p)$$\n",
    ", where $p=x_{t}^{est}$, the previous optimal estimate, and $\\mathbf{H}_t$ is the Jacobian matrix at time step $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Kalman Filter example in the Pyro website, now we have predictions and updates rules as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T14:22:30.923114Z",
     "start_time": "2019-10-28T14:22:30.913687Z"
    }
   },
   "source": [
    "#### The predictions are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\mathbf{X}}_t \\approx \\mathbf{f}(\\mathbf{X}_{t-1}^{est})$$\n",
    "$$\\mathbf{Y}_t = \\mathbf{H_f}(\\mathbf{X}_{t-1})\\mathbf{Y}_{t-1}\\mathbf{H_f}^T(\\mathbf{X}_{t-1})+\\mathbf{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The updates are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathbf{X_t} \\approx \\hat{\\mathbf{X}}_t+\\mathbf{K}_t\\left(y_t-\\mathbf h(\\hat{\\mathbf{X}}_t)\\right)$$\n",
    "$$K_t=\\hat{P}_t\\mathbf{H_h}(\\hat{\\mathbf{X}}_t)\\left(\\mathbf{H_h}(\\hat{\\mathbf{X}}_t)\\hat{P}_t\\mathbf{H_h}(\\hat{\\mathbf{X}}_t)+R_t\\right)^{-1}$$\n",
    "$$P_t = \\left(I-K_t\\mathbf{H_h}(\\hat{\\mathbf{X}}_t)\\right)\\hat{P}_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyro implementation\n",
    "- I follow the example in Pyro website to practice for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:46:38.692556Z",
     "start_time": "2019-10-28T16:46:37.800398Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, config_enumerate\n",
    "from pyro.contrib.tracking.extended_kalman_filter import EKFState\n",
    "from pyro.contrib.tracking.distributions import EKFDistribution\n",
    "from pyro.contrib.tracking.dynamic_models import NcvContinuous\n",
    "from pyro.contrib.tracking.measurements import PositionMeasurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to the following link, having the two lines of codes are the **best practices** without further explanation: https://github.com/pyro-ppl/pyro/issues/930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:46:38.692556Z",
     "start_time": "2019-10-28T16:46:37.800398Z"
    }
   },
   "outputs": [],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('0.4.1')\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:54:18.612274Z",
     "start_time": "2019-10-28T16:54:18.570174Z"
    }
   },
   "outputs": [],
   "source": [
    "dt = 1e-2\n",
    "num_frames = 10\n",
    "dim = 4\n",
    "\n",
    "# Continuous model\n",
    "ncv = NcvContinuous(dim, 2.0)\n",
    "\n",
    "# Truth trajectory\n",
    "xs_truth = torch.zeros(num_frames, dim)\n",
    "# initial direction\n",
    "theta0_truth = 0.0\n",
    "# initial state\n",
    "with torch.no_grad():\n",
    "    xs_truth[0, :] = torch.tensor(\n",
    "        [0.0, 0.0,  math.cos(theta0_truth), math.sin(theta0_truth)])\n",
    "    for frame_num in range(1, num_frames):\n",
    "        # sample independent process noise\n",
    "        dx = pyro.sample('process_noise_{}'.format(\n",
    "            frame_num), ncv.process_noise_dist(dt))\n",
    "        xs_truth[frame_num, :] = ncv(xs_truth[frame_num-1, :], dt=dt) + dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:54:41.111682Z",
     "start_time": "2019-10-28T16:54:41.096953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
       "        [ 9.9298e-03, -4.2019e-05,  9.9879e-01, -6.2927e-03],\n",
       "        [ 1.9858e-02, -1.3703e-04,  9.8131e-01, -6.4835e-03],\n",
       "        [ 2.9670e-02, -1.3280e-04,  9.8039e-01,  5.1214e-03],\n",
       "        [ 3.9381e-02,  9.5771e-06,  9.5822e-01,  2.0339e-02],\n",
       "        [ 4.9010e-02,  1.4353e-04,  9.6450e-01,  1.8807e-02],\n",
       "        [ 5.8850e-02,  2.9863e-04,  9.8926e-01,  1.6081e-02],\n",
       "        [ 6.8766e-02,  5.4268e-04,  9.9629e-01,  2.1323e-02],\n",
       "        [ 7.8719e-02,  7.1544e-04,  1.0032e+00,  1.4204e-02],\n",
       "        [ 8.8778e-02,  8.4070e-04,  1.0087e+00,  1.1806e-02]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T17:39:05.134156Z",
     "start_time": "2019-10-28T17:39:05.129238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T17:09:37.230697Z",
     "start_time": "2019-10-28T17:09:37.221704Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1\n",
      "dsz tensor([[ 1.9301e-03,  1.4764e-03],\n",
      "        [ 6.1685e-03, -3.3618e-03],\n",
      "        [-2.6227e-03, -4.4501e-03],\n",
      "        [ 5.1445e-03,  5.4478e-04],\n",
      "        [-5.0960e-03, -1.5161e-03],\n",
      "        [-4.5332e-04, -1.0034e-03],\n",
      "        [ 1.8141e-03,  3.1557e-03],\n",
      "        [ 1.7190e-03,  2.4920e-04],\n",
      "        [ 2.7286e-03, -6.1632e-05],\n",
      "        [ 3.1340e-03, -2.4594e-03]])\n",
      "zs tensor([[ 0.0019,  0.0015],\n",
      "        [ 0.0161, -0.0034],\n",
      "        [ 0.0172, -0.0046],\n",
      "        [ 0.0348,  0.0004],\n",
      "        [ 0.0343, -0.0015],\n",
      "        [ 0.0486, -0.0009],\n",
      "        [ 0.0607,  0.0035],\n",
      "        [ 0.0705,  0.0008],\n",
      "        [ 0.0814,  0.0007],\n",
      "        [ 0.0919, -0.0016]])\n"
     ]
    }
   ],
   "source": [
    "measurements = []\n",
    "mean = torch.zeros(2)\n",
    "# no correlations\n",
    "cov = 1e-5 * torch.eye(2)\n",
    "i=1\n",
    "with torch.no_grad():\n",
    "    # sample independent measurement noise\n",
    "    dzs = pyro.sample('dzs', dist.MultivariateNormal(mean, cov).expand((num_frames,)))\n",
    "    print(\"#{:2d}\".format(i))\n",
    "    print('dsz', dzs)\n",
    "    # compute measurement means\n",
    "    zs = xs_truth[:, :2] + dzs\n",
    "    print('zs', zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:55:34.606569Z",
     "start_time": "2019-10-28T16:55:34.601785Z"
    }
   },
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # a HalfNormal can be used here as well\n",
    "    R = pyro.sample('pv_cov', dist.HalfCauchy(2e-6)) * torch.eye(4)\n",
    "    Q = pyro.sample('measurement_cov', dist.HalfCauchy(1e-6)) * torch.eye(2)\n",
    "    # observe the measurements\n",
    "    pyro.sample('track_{}'.format(i), EKFDistribution(xs_truth[0], R, ncv,\n",
    "                                                      Q, time_steps=num_frames),\n",
    "                obs=data)\n",
    "\n",
    "guide = AutoDelta(model)  # MAP estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T17:12:07.539516Z",
     "start_time": "2019-10-28T17:12:03.131029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#  0 loss: -16.5052490234375\n",
      "# 10 loss: -16.558531761169434\n",
      "# 20 loss: -16.588309288024902\n",
      "# 30 loss: -16.603419303894043\n",
      "# 40 loss: -16.61054801940918\n",
      "# 50 loss: -16.613832473754883\n",
      "# 60 loss: -16.6153564453125\n",
      "# 70 loss: -16.616074562072754\n",
      "# 80 loss: -16.61642074584961\n",
      "# 90 loss: -16.61659049987793\n",
      "#100 loss: -16.616674423217773\n",
      "#110 loss: -16.61671733856201\n",
      "#120 loss: -16.616735458374023\n",
      "#130 loss: -16.616744995117188\n",
      "#140 loss: -16.616750717163086\n",
      "#150 loss: -16.61675262451172\n",
      "#160 loss: -16.616753578186035\n",
      "#170 loss: -16.616753578186035\n",
      "#180 loss: -16.616753578186035\n",
      "#190 loss: -16.616756439208984\n",
      "#200 loss: -16.616753578186035\n",
      "#210 loss: -16.616755485534668\n",
      "#220 loss: -16.61675453186035\n",
      "#230 loss: -16.61675453186035\n",
      "#240 loss: -16.61675453186035\n"
     ]
    }
   ],
   "source": [
    "optim = pyro.optim.Adam({'lr': 2e-2})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO(retain_graph=True))\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "for i in range(250 if not smoke_test else 2):\n",
    "    loss = svi.step(zs)\n",
    "    if not i % 10:\n",
    "        print('#{:3d} loss: {}'.format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:55:56.505894Z",
     "start_time": "2019-10-28T16:55:56.495510Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# retrieve states for visualization\n",
    "R = guide()['pv_cov'] * torch.eye(4)\n",
    "Q = guide()['measurement_cov'] * torch.eye(2)\n",
    "ekf_dist = EKFDistribution(xs_truth[0], R, ncv, Q, time_steps=num_frames)\n",
    "states= ekf_dist.filter_states(zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:56:08.825947Z",
     "start_time": "2019-10-28T16:56:08.821763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x113b55470>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x113ab6898>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x113b55160>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d908>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d780>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d208>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d6d8>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d128>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d940>,\n",
       " <pyro.contrib.tracking.extended_kalman_filter.EKFState at 0x11397d320>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:56:36.793159Z",
     "start_time": "2019-10-28T16:56:36.782489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4523e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.4523e-06, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 1.4523e-06, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4523e-06]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:56:41.018105Z",
     "start_time": "2019-10-28T16:56:41.013776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5117e-07, 0.0000e+00],\n",
       "        [0.0000e+00, 2.5117e-07]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T16:56:49.117700Z",
     "start_time": "2019-10-28T16:56:49.114448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EKFDistribution(measurement_cov: torch.Size([2, 2]), P0: torch.Size([4, 4]), x0: torch.Size([4]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekf_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
